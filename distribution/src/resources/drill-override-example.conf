# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#  This file tells Drill to consider this module when class path scanning.  
#  This file can also include any supplementary configuration information.  
#  This file is in HOCON format, see https://github.com/typesafehub/config/blob/master/HOCON.md for more information.

drill.logical.function.packages += "org.apache.drill.exec.expr.fn.impl"

drill.exec: {
  cluster-id: "drillbits1"
  rpc: {
    user: {
      server: {
        port: 31010
        threads: 1
      }
      client: {
        threads: 1
      }
    },
    bit: {
      server: {
        port : 31011,
        retry:{
          count: 7200,
          delay: 500
        },
        threads: 1
      }
    },
  	use.ip : false
  },
  operator: {
    packages += "org.apache.drill.exec.physical.config"
  },
  optimizer: {
    implementation: "org.apache.drill.exec.opt.IdentityOptimizer"
  },
  functions: ["org.apache.drill.expr.fn.impl"],
  storage: {
    packages += "org.apache.drill.exec.store",
    file: {
      text: {
        buffer.size: 262144,
        batch.size: 4000
      },
      partition.column.label: "dir"
    }
  },
  metrics : {
    context: "drillbit",
    jmx: {
      enabled : true
    },
    log: {
      enabled : false,
      interval : 60
    }
  },
  zk: {
	connect: "localhost:2181",
	root: "drill",
	refresh: 500,
	timeout: 5000,
  	retry: {
  	  count: 7200,
  	  delay: 500
  	}
  },
  http: {
    enabled: true,
    ssl_enabled: false,
    port: 8047
    session_max_idle_secs: 3600, # Default value 1hr
    cors: {
      enabled: false,
      allowedOrigins: ["null"],
      allowedMethods: ["GET", "POST", "HEAD", "OPTIONS"],
      allowedHeaders: ["X-Requested-With", "Content-Type", "Accept", "Origin"],
      credentials: true
    }
  },
  functions: ["org.apache.drill.expr.fn.impl"],
  network: {
    start: 35000
  },
  work: {
    max.width.per.endpoint: 5,
    global.max.width: 100,
    affinity.factor: 1.2,
    executor.threads: 4
  },
  sys.store.provider: {
    class: "org.apache.drill.exec.store.sys.store.provider.ZookeeperPersistentStoreProvider",
    # The following section is used by ZkPStoreProvider
    zk: {
      blobroot: "file:///var/log/drill"
    },
    # The following section is only required by LocalPStoreProvider
    local: {
      path: "/tmp/drill",
      write: true
    }
  },
  impersonation: {
    enabled: false,
    max_chained_user_hops: 3
  },
  security.user.auth {
    enabled: false,
    packages += "org.apache.drill.exec.rpc.user.security",
    impl: "pam",
    pam_profiles: [ "sudo", "login" ]
  },
  trace: {
    directory: "/tmp/drill-trace",
    filesystem: "file:///"
  },
  tmp: {
    directories: ["/tmp/drill"],
    filesystem: "drill-local:///"
  },
  buffer:{
    impl: "org.apache.drill.exec.work.batch.UnlimitedRawBatchBuffer",
    size: "100",
    spooling: {
      delete: false,
      size: 100000000
    }
  },
  cache.hazel.subnets: ["*.*.*.*"],
  sort: {
    purge.threshold : 100,
    external: {
      batch.size : 4000,
      spill: {
        batch.size : 4000,
        group.size : 100,
        threshold : 200,
        directories : [ "/tmp/drill/spill" ],
        fs : "file:///"
      }
    }
  },
  memory: {
    top.max: 1000000000000,
    operator: {
      max: 20000000000,
      initial: 10000000
    },
    fragment: {
      max: 20000000000,
      initial: 20000000
    }
  },
  scan: {
    threadpool_size: 8,
    decode_threadpool_size: 1
  },
  debug.error_on_leak: true,
  # Settings for Dynamic UDFs.
  # See https://gist.github.com/arina-ielchiieva/a1c4cfa3890145c5ecb1b70a39cbff55#file-dynamicudfssupport-md.
  udf: {
    # number of retry attempts to update remote function registry
    # if registry version was changed during update
    retry-attempts: 10,
    directory: {
      # Override this property if custom file system should be used to create remote directories
      # instead of default taken from Hadoop configuration
      fs: "hdfs:///",
      # Set this property if custom absolute root should be used for remote directories
      root: "/app/drill"
    }
  }
}

# Below SSL parameters need to be set for custom transport layer settings.
javax.net.ssl {
  keyStore: "/keystore.file",
  keyStorePassword: "ks_passwd",
  trustStore: "/truststore.file",
  trustStorePassword: "ts_passwd"
}

